#!/usr/bin/env python3
"""í†µí•©ê³µê³  PDF â†’ JSONL íŒŒì„œ"""

import fitz
import json
import re
from pathlib import Path

PDF_PATH = Path(os.environ.get("RAON_PDF_PATH", str(Path(__file__).parent.parent / "drafts" / "gov" / "2026-í†µí•©ê³µê³ .pdf")))
OUT_PATH = Path(__file__).resolve().parent.parent / "eval_data" / "unified_announcement_2026.jsonl"


def extract_all_text(pdf_path: Path) -> str:
    doc = fitz.open(str(pdf_path))
    texts = []
    for page in doc:
        texts.append(page.get_text())
    return "\n".join(texts)


def extract_tables(pdf_path: Path) -> list[dict]:
    """Extract program entries from PDF tables."""
    doc = fitz.open(str(pdf_path))
    programs = []
    
    # Strategy: extract tables page by page using PyMuPDF table extraction
    for page_num in range(len(doc)):
        page = doc[page_num]
        tables = page.find_tables()
        for table in tables:
            data = table.extract()
            if not data:
                continue
            # Find header row
            header_idx = -1
            for i, row in enumerate(data):
                row_text = " ".join(str(c) for c in row if c)
                if "ì‚¬ì—…ëª…" in row_text and "ì‚¬ì—…ê°œìš”" in row_text:
                    header_idx = i
                    break
            
            start = header_idx + 1 if header_idx >= 0 else 0
            # If no header found and this doesn't look like program data, skip
            if header_idx < 0:
                # Check if rows look like program entries (have numbers and Korean text)
                if not any(row[0] and str(row[0]).strip().isdigit() for row in data if row and row[0]):
                    continue
            
            for row in data[start:]:
                if not row or len(row) < 5:
                    continue
                cells = [str(c).strip() if c else "" for c in row]
                
                # Skip empty or header rows
                if not any(cells):
                    continue
                if "ì‚¬ì—…ëª…" in cells[0] or "ì—°ë²ˆ" in " ".join(cells[:2]):
                    continue
                
                # Try to parse based on column count
                prog = {}
                if len(cells) >= 8:
                    # Standard: ì—°ë²ˆ, ì‚¬ì—…ëª…, ì‚¬ì—…ê°œìš”, ì§€ì›ë‚´ìš©, ì§€ì›ëŒ€ìƒ, ì˜ˆì‚°, ê³µê³ ì¼, ì†Œê´€ë¶€ì²˜, ì£¼ê´€ê¸°ê´€, ë¹„ê³ 
                    idx = 0
                    # Skip ì—°ë²ˆ if it's a number
                    if cells[0].replace('.', '').strip().isdigit():
                        idx = 1
                    prog["program"] = cells[idx].replace("ã†", "").strip()
                    prog["description"] = cells[idx+1] if idx+1 < len(cells) else ""
                    prog["support_content"] = cells[idx+2] if idx+2 < len(cells) else ""
                    prog["target"] = cells[idx+3] if idx+3 < len(cells) else ""
                    prog["budget"] = cells[idx+4] if idx+4 < len(cells) else ""
                    prog["announcement_date"] = cells[idx+5] if idx+5 < len(cells) else ""
                    prog["ministry"] = cells[idx+6] if idx+6 < len(cells) else ""
                    prog["agency"] = cells[idx+7] if idx+7 < len(cells) else ""
                
                if prog.get("program") and len(prog["program"]) > 1:
                    programs.append(prog)
    
    return programs


def fallback_text_parse(pdf_path: Path) -> list[dict]:
    """Fallback: parse from raw text using regex patterns."""
    doc = fitz.open(str(pdf_path))
    programs = []
    
    full_text = ""
    for page in doc:
        full_text += page.get_text() + "\n"
    
    # Pattern: look for numbered entries with ã† prefix for program names
    # Split by numbered entries
    pattern = re.compile(
        r'(\d+)\s*\n?\s*ã†([^\n]+)',
        re.MULTILINE
    )
    
    matches = list(pattern.finditer(full_text))
    
    for i, match in enumerate(matches):
        num = match.group(1).strip()
        name = match.group(2).strip()
        
        # Get text until next match
        start = match.end()
        end = matches[i+1].start() if i+1 < len(matches) else start + 2000
        block = full_text[start:end].strip()
        
        prog = {
            "program": name,
            "description": "",
            "support_content": "",
            "target": "",
            "budget": "",
            "announcement_date": "",
            "ministry": "",
            "agency": "",
        }
        
        # Try to extract budget (ì–µì›)
        budget_match = re.search(r'([\d,]+)\s*\n?\s*\d{2,4}[.\së…„]', block)
        if budget_match:
            prog["budget"] = budget_match.group(1).strip() + "ì–µì›"
        
        # Extract ministry
        ministry_patterns = [
            r'(ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€|ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€|ì‚°ì—…í†µìƒìì›ë¶€|ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€|ë¬¸í™”ì²´ìœ¡ê´€ê´‘ë¶€|'
            r'êµ­í† êµí†µë¶€|í™˜ê²½ë¶€|ê¸°í›„ì—ë„ˆì§€í™˜ê²½ë¶€|ë³´ê±´ë³µì§€ë¶€|êµìœ¡ë¶€|ê³ ìš©ë…¸ë™ë¶€|'
            r'í•´ì–‘ìˆ˜ì‚°ë¶€|êµ­ë°©ë¶€|í–‰ì •ì•ˆì „ë¶€|ì—¬ì„±ê°€ì¡±ë¶€|ì™¸êµë¶€|í†µì¼ë¶€|ë²•ë¬´ë¶€|'
            r'ê¸°íšì¬ì •ë¶€|íŠ¹í—ˆì²­|ê´€ì„¸ì²­|ë°©ìœ„ì‚¬ì—…ì²­|ì‚°ë¦¼ì²­|ê¸°ìƒì²­|ì†Œë°©ì²­|ê²½ì°°ì²­|'
            r'ë°©ì†¡í†µì‹ ìœ„ì›íšŒ|ê³µì •ê±°ë˜ìœ„ì›íšŒ|ê¸ˆìœµìœ„ì›íšŒ|ì›ìë ¥ì•ˆì „ìœ„ì›íšŒ|'
            r'êµ­ê°€ë³´í›ˆë¶€|ì‹í’ˆì˜ì•½í’ˆì•ˆì „ì²˜)'
        ]
        for mp in ministry_patterns:
            m = re.search(mp, block)
            if m:
                prog["ministry"] = m.group(1)
                break
        
        # Extract announcement date
        date_match = re.search(r"(\d{2,4})[.ë…„]\s*(\d{1,2})ì›”", block)
        if date_match:
            prog["announcement_date"] = f"{date_match.group(1)}.{date_match.group(2)}ì›”"
        
        # Use first ~200 chars as description
        desc_text = block[:300].replace("\n", " ").strip()
        prog["description"] = desc_text
        
        if name and len(name) > 1:
            programs.append(prog)
    
    return programs


def main():
    print("ğŸ“„ í†µí•©ê³µê³  PDF íŒŒì‹± ì‹œì‘...")
    
    # Try table extraction first
    programs = extract_tables(PDF_PATH)
    print(f"  í…Œì´ë¸” ì¶”ì¶œ: {len(programs)}ê±´")
    
    # If table extraction got few results, try text parsing
    if len(programs) < 100:
        print("  í…Œì´ë¸” ì¶”ì¶œ ë¶€ì¡±, í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ ë³´ì™„...")
        text_programs = fallback_text_parse(PDF_PATH)
        print(f"  í…ìŠ¤íŠ¸ íŒŒì‹±: {len(text_programs)}ê±´")
        
        # Merge: use text_programs if significantly more
        existing_names = {p["program"] for p in programs}
        for tp in text_programs:
            if tp["program"] not in existing_names:
                programs.append(tp)
                existing_names.add(tp["program"])
        print(f"  ë³‘í•© í›„: {len(programs)}ê±´")
    
    # Write JSONL
    OUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    with open(OUT_PATH, "w") as f:
        for prog in programs:
            entry = {
                "type": "gov_program",
                "source": "2026-í†µí•©ê³µê³ ",
                "program": prog["program"],
                "description": prog.get("description", ""),
                "support_content": prog.get("support_content", ""),
                "target": prog.get("target", ""),
                "budget": prog.get("budget", ""),
                "announcement_date": prog.get("announcement_date", ""),
                "ministry": prog.get("ministry", ""),
                "agency": prog.get("agency", ""),
            }
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")
    
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {OUT_PATH} ({len(programs)}ê±´)")


if __name__ == "__main__":
    main()
