# ğŸª™ Token Optimizer

**Reduce OpenClaw token usage and API costs by 85-95%**

An OpenClaw skill that implements smart model routing, lazy context loading, optimized heartbeats, and multi-provider support for maximum cost savings.

[![ClawHub](https://img.shields.io/badge/ClawHub-Ready-blue)](https://clawhub.ai)
[![Version](https://img.shields.io/badge/version-1.2.2-green)](https://github.com/Asif2BD/OpenClaw-Token-Optimizer/blob/main/CHANGELOG.md)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![OpenClaw](https://img.shields.io/badge/OpenClaw-Skill-purple)](https://openclaw.ai)

---

## ğŸš€ One-Line Installation

```bash
git clone https://github.com/Asif2BD/OpenClaw-Token-Optimizer.git ~/.openclaw/skills/token-optimizer
```

**Done!** Your agent now has access to token optimization tools.

### Alternative: Tell Your Agent

> "Install the token-optimizer skill from github.com/Asif2BD/OpenClaw-Token-Optimizer"

Your agent will clone it to the skills directory automatically.

---

## ğŸ¯ Quick Start

### 1. Generate Optimized AGENTS.md (Biggest Win!)

```bash
python3 ~/.openclaw/skills/token-optimizer/scripts/context_optimizer.py generate-agents
# Creates AGENTS.md.optimized â€” review and replace your current AGENTS.md
```

This teaches your agent to load only the context it needs (70-90% context reduction!).

### 2. Route Tasks to Appropriate Models

```bash
# Check what model to use for a prompt
python3 ~/.openclaw/skills/token-optimizer/scripts/model_router.py "thanks!"
# â†’ Output: Use cheap tier (Haiku/Nano/Flash), not Opus!

python3 ~/.openclaw/skills/token-optimizer/scripts/model_router.py "design a microservices architecture"
# â†’ Output: Use smart tier (Opus/GPT-4.1/Pro)
```

### 3. Install Optimized Heartbeat

```bash
cp ~/.openclaw/skills/token-optimizer/assets/HEARTBEAT.template.md ~/.openclaw/workspace/HEARTBEAT.md
```

### 4. Check Token Budget

```bash
python3 ~/.openclaw/skills/token-optimizer/scripts/token_tracker.py check
```

**Expected savings:** 85-95% reduction in token costs for typical workloads.

---

## ğŸ“¦ What's Included

### Scripts

| Script | Purpose | Savings |
|--------|---------|---------|
| `context_optimizer.py` | Lazy context loading â€” only load needed files | 70-90% |
| `model_router.py` | Smart model selection with multi-provider support | 60-98% |
| `heartbeat_optimizer.py` | Efficient heartbeat scheduling | 90-95% |
| `token_tracker.py` | Budget monitoring and alerts | Prevents overruns |


### Assets

| File | Purpose |
|------|---------|
| `HEARTBEAT.template.md` | Drop-in optimized heartbeat template |
| `cronjob-model-guide.md` | Guide for choosing models in cronjobs |
| `config-patches.json` | Advanced configuration examples |

### References

| File | Purpose |
|------|---------|
| `PROVIDERS.md` | Alternative AI providers, pricing, routing strategies |

---

## ğŸŒ Multi-Provider Support

The skill supports multiple AI providers with automatic detection:

| Provider | Cheap Tier | Balanced Tier | Smart Tier |
|----------|------------|---------------|------------|
| **Anthropic** | claude-haiku-4 | claude-sonnet-4-5 | claude-opus-4 |
| **OpenAI** | gpt-4.1-nano | gpt-4.1-mini | gpt-4.1 |
| **Google** | gemini-2.0-flash | gemini-2.5-flash | gemini-2.5-pro |
| **OpenRouter** | gemini-2.0-flash | claude-sonnet-4-5 | claude-opus-4 |

Set your preferred provider via environment variable:

```bash
export ANTHROPIC_API_KEY="sk-ant-..."   # Default
export OPENAI_API_KEY="sk-proj-..."     # For OpenAI routing
export GOOGLE_API_KEY="AIza..."         # For Google routing
export OPENROUTER_API_KEY="sk-or-..."   # For unified API
```

The model router auto-detects which provider to use based on available keys.

```bash
# Compare models across all providers
python3 scripts/model_router.py compare

# Force specific provider
python3 scripts/model_router.py "thanks" --provider openai
```

---

## ğŸ’¡ Core Optimization Strategies

### 1. Context Optimization (Biggest Win!)

**Problem:** Default OpenClaw loads ALL context files â€” often 50K+ tokens before the user speaks.

**Solution:** Load only what's needed based on prompt complexity.

```bash
# Simple greeting â†’ minimal context (2 files only!)
python3 scripts/context_optimizer.py recommend "hi"
# â†’ Load: SOUL.md, IDENTITY.md (savings: ~80%)

# Complex task â†’ full context
python3 scripts/context_optimizer.py recommend "analyze architecture"
# â†’ Load: SOUL.md, IDENTITY.md, MEMORY.md, etc. (savings: ~30%)
```

### 2. Smart Model Routing

**Problem:** Using Opus ($15/MTok) for "thanks!" is wasteful.

**Solution:** Route to appropriate tier based on task.

```bash
# Communication â†’ ALWAYS cheap tier
python3 scripts/model_router.py "thanks!"
# â†’ anthropic/claude-haiku-4 (or openai/gpt-4.1-nano)

# Complex task â†’ smart tier (only when needed)
python3 scripts/model_router.py "design a microservices architecture"
# â†’ anthropic/claude-opus-4
```

### 3. Heartbeat Optimization

**Problem:** Checking email every 5 minutes at 3 AM wastes tokens.

**Solution:** Smart intervals + quiet hours.

```bash
python3 scripts/heartbeat_optimizer.py plan
# â†’ Checks what needs checking, skips during quiet hours
```

---

## ğŸ“Š Cost Savings Analysis (v1.2.0 Revised)

### Why 85-95% Savings?

Our initial estimates (50-80%) were conservative. Here's the realistic breakdown:

#### 1. Lazy Context Loading (70-90% context reduction)

| Task Type | % of Traffic | Context Loaded | Reduction |
|-----------|--------------|----------------|-----------|
| Simple chat/greetings | 60-70% | SOUL.md + IDENTITY.md only | **90%** |
| Standard work | 20-30% | + Today's memory | **70%** |
| Complex tasks | 10% | Full context | **30%** |

**Weighted average:** 60% Ã— 90% + 30% Ã— 70% + 10% Ã— 30% = **78% context reduction**

#### 2. Model Routing (60-98% cost per token)

| Task Type | Cloud Model | Local/Cheap Model | Savings |
|-----------|-------------|-------------------|---------|
| Simple chat | Sonnet ($3/M) | Haiku ($0.25/M) | **92%** |
| Greetings | Sonnet ($3/M) | Haiku ($0.25/M) | **92%** |
| Complex | Sonnet ($3/M) | Sonnet ($3/M) | 0% |

**Weighted average:** 70% Ã— 92% + 30% Ã— 0% = **64% model cost reduction**

#### 3. Combined Effect (Multiplicative!)

```
Total Savings = 1 - (Context Remaining Ã— Model Cost Remaining)
             = 1 - (0.22 Ã— 0.36)
             = 1 - 0.08
             = 92% savings
```

#### 4. Heartbeat Optimization (90-95% savings)

| Optimization | Reduction |
|--------------|-----------|
| Quiet hours (8h/day) | 33% fewer calls |
| Haiku instead of Sonnet | 92% cheaper per call |
| Batching/skip redundant | 20% fewer calls |
| **Combined** | **~95% heartbeat savings** |

### Monthly Cost Examples

| Scenario | Before | After | Savings |
|----------|--------|-------|---------|
| Light usage (50K tokens/day) | $4.50/mo | $0.45/mo | **90%** |
| Medium usage (200K tokens/day) | $18.00/mo | $1.80/mo | **90%** |
| Heavy usage (1M tokens/day) | $90.00/mo | $9.00/mo | **90%** |
| + Local fallback when offline | Any | $0.00 | **100%** |

### Cronjob Savings

Using Haiku instead of Opus for 10 daily cronjobs:
- **Before:** 10 Ã— 5K tokens Ã— $15/MTok = $0.75/day = **$22.50/month**
- **After:** 10 Ã— 5K tokens Ã— $0.25/MTok = $0.0125/day = **$0.38/month**
- **Savings: $22/month per agent** (98% reduction)

---

## ğŸ›¸ Local Model Fallback (Emergency Fuel Mode)

**NEW in v1.2.0!** When cloud APIs fail, your agent keeps running on local models.

### Quick Setup

```bash
```

### Configure OpenClaw

Add to `~/.openclaw/config.json`:

```json
{
  "models": {
    "providers": {
      }
    }
  },
  "agents": {
    "defaults": {
      "model": {
      }
    }
  }
}
```

### Benefits

| Benefit | Description |
|---------|-------------|
| ğŸ’° Zero cost | No API charges when on local |
| ğŸš« No rate limits | Process unlimited requests |
| ğŸ“¡ Works offline | No internet required |
| ğŸ”’ Privacy | Data never leaves your machine |


---

## ğŸ“‹ Changelog

See [CHANGELOG.md](CHANGELOG.md) for full version history.

### v1.2.0 (2026-02-06)
- ğŸ›¸ **Local model fallback** (Emergency Fuel Mode) with Ollama integration
- ğŸ“Š **Revised savings estimates** â€” now 85-95% (was 50-80%)
- ğŸ“ Detailed cost analysis with real calculations

### v1.1.0 (2026-02-06)
- âœ¨ **Multi-provider support**: OpenAI, Google, OpenRouter
- ğŸ·ï¸ Provider-agnostic tier system (cheap/balanced/smart)
- ğŸ“¦ ClawHub-ready SKILL.md with proper metadata
- ğŸ“ One-line installation instructions

### v1.0.0 (2026-02-05)
- ğŸ‰ Initial release
- Context optimizer, model router, heartbeat optimizer, token tracker
- Comprehensive documentation and examples

---

## ğŸ”§ Requirements

- Python 3.7+ (stdlib only, no external dependencies)
- OpenClaw installation
- Write access to `~/.openclaw/workspace/memory/`

---

## ğŸ“ Project Structure

```
token-optimizer/
â”œâ”€â”€ SKILL.md              # Skill definition (ClawHub-ready)
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ CHANGELOG.md          # Version history
â”œâ”€â”€ LICENSE               # MIT License
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ context_optimizer.py   # Context loading optimization
â”‚   â”œâ”€â”€ model_router.py        # Multi-provider model routing
â”‚   â”œâ”€â”€ heartbeat_optimizer.py # Heartbeat interval management
â”‚   â””â”€â”€ token_tracker.py       # Budget monitoring
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ HEARTBEAT.template.md  # Drop-in heartbeat template
â”‚   â”œâ”€â”€ cronjob-model-guide.md # Cronjob model selection guide
â”‚   â””â”€â”€ config-patches.json    # Advanced config examples
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ RESEARCH-NOTES.md      # Research and methodology
â””â”€â”€ references/
    â””â”€â”€ PROVIDERS.md           # Provider comparison guide
```

---

## ğŸ“– Full Documentation

See [SKILL.md](SKILL.md) for complete documentation including:
- All script options and examples
- Integration patterns
- Workflow examples
- Troubleshooting guide

---

## ğŸ¤ Contributing

Contributions welcome! Please open an issue or PR.

**Ideas for extending this skill:**
1. Auto-routing integration with OpenClaw message pipeline
2. Real-time usage tracking via session_status parsing
3. Cost forecasting based on recent usage
4. Provider health monitoring
5. A/B testing for routing strategies
6. Automatic local model selection based on task type
7. Hybrid mode: local for simple, cloud for complex

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ™ Credits

Part of the **SuperSkills** collection for OpenClaw.

Created by:
- **Oracle** â€” Research, analysis, and documentation
- **Morpheus** â€” Code review and publication

---

*"The best token is the one you don't spend."* ğŸª™
